{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install tensorflow==2.13.0","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nprint(\"TensorFlow version:\", tf.__version__)\nimport os\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom tensorflow import keras \nfrom keras import optimizers\nfrom keras import applications\nfrom keras.models import Model\nfrom keras.models import load_model","metadata":{"execution":{"iopub.status.busy":"2023-07-27T12:56:20.261493Z","iopub.execute_input":"2023-07-27T12:56:20.261817Z","iopub.status.idle":"2023-07-27T12:56:20.266685Z","shell.execute_reply.started":"2023-07-27T12:56:20.261786Z","shell.execute_reply":"2023-07-27T12:56:20.265824Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"TensorFlow version: 2.12.0\n","output_type":"stream"}]},{"cell_type":"code","source":"mnist = tf.keras.datasets.mnist\n(x_train, y_train), (x_test, y_test) = mnist.load_data()\n","metadata":{"execution":{"iopub.status.busy":"2023-07-27T12:59:41.371960Z","iopub.execute_input":"2023-07-27T12:59:41.372317Z","iopub.status.idle":"2023-07-27T12:59:42.654889Z","shell.execute_reply.started":"2023-07-27T12:59:41.372291Z","shell.execute_reply":"2023-07-27T12:59:42.653630Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n11490434/11490434 [==============================] - 1s 0us/step\n","output_type":"stream"}]},{"cell_type":"code","source":"type(x_train[0][0][0])","metadata":{"execution":{"iopub.status.busy":"2023-07-27T13:16:55.427949Z","iopub.execute_input":"2023-07-27T13:16:55.428301Z","iopub.status.idle":"2023-07-27T13:16:55.434148Z","shell.execute_reply.started":"2023-07-27T13:16:55.428277Z","shell.execute_reply":"2023-07-27T13:16:55.433524Z"},"trusted":true},"execution_count":29,"outputs":[{"execution_count":29,"output_type":"execute_result","data":{"text/plain":"numpy.uint8"},"metadata":{}}]},{"cell_type":"code","source":"# Sequential is useful for stacking layers where each layer has one input tensor \n# and one output tensor. Layers are functions with a known mathematical structure \n# that can be reused and have trainable variables. Most TensorFlow models are\n# composed of layers. This model uses the Flatten, Dense, and Dropout layers.\n\nmodel = tf.keras.models.Sequential([\n    tf.keras.layers.Flatten(input_shape=(28,28)),\n    tf.keras.layers.Dense(128, activation='relu'),\n    tf.keras.layers.Dropout(0.2),\n    tf.keras.layers.Dense(10)\n])","metadata":{"execution":{"iopub.status.busy":"2023-07-27T13:07:48.601269Z","iopub.execute_input":"2023-07-27T13:07:48.601649Z","iopub.status.idle":"2023-07-27T13:07:48.750102Z","shell.execute_reply.started":"2023-07-27T13:07:48.601619Z","shell.execute_reply":"2023-07-27T13:07:48.749401Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"# For each example, the model returns a vector of logits or log-odds scores, \n# one for each class.\n\npredictions = model(x_train[:1]).numpy()\n\n# The tf.nn.softmax function converts these logits to probabilities for each class: \ntf.nn.softmax(predictions).numpy()\n","metadata":{"execution":{"iopub.status.busy":"2023-07-27T13:17:58.140846Z","iopub.execute_input":"2023-07-27T13:17:58.141166Z","iopub.status.idle":"2023-07-27T13:17:58.155453Z","shell.execute_reply.started":"2023-07-27T13:17:58.141141Z","shell.execute_reply":"2023-07-27T13:17:58.154585Z"},"trusted":true},"execution_count":32,"outputs":[{"execution_count":32,"output_type":"execute_result","data":{"text/plain":"array([[0., 0., 0., 0., 0., 0., 0., 0., 1., 0.]], dtype=float32)"},"metadata":{}}]},{"cell_type":"code","source":"# Define a loss function for training using losses.SparseCategoricalCrossentropy:\nloss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n\n# The loss function takes a vector of ground truth values and a vector of logits\n# and returns a scalar loss for each example. This loss is equal to the negative\n# log probability of the true class: The loss is zero if the model is sure of the\n# correct class.","metadata":{"execution":{"iopub.status.busy":"2023-07-27T13:31:38.503972Z","iopub.execute_input":"2023-07-27T13:31:38.504356Z","iopub.status.idle":"2023-07-27T13:31:38.509477Z","shell.execute_reply.started":"2023-07-27T13:31:38.504330Z","shell.execute_reply":"2023-07-27T13:31:38.508271Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"# This untrained model gives probabilities close to random (1/10 for each class),\n# so the initial loss should be close to -tf.math.log(1/10) ~= 2.3.\nloss_fn(y_train[:1], predictions).numpy()","metadata":{"execution":{"iopub.status.busy":"2023-07-27T13:32:59.768614Z","iopub.execute_input":"2023-07-27T13:32:59.768948Z","iopub.status.idle":"2023-07-27T13:32:59.787651Z","shell.execute_reply.started":"2023-07-27T13:32:59.768923Z","shell.execute_reply":"2023-07-27T13:32:59.786253Z"},"trusted":true},"execution_count":35,"outputs":[{"execution_count":35,"output_type":"execute_result","data":{"text/plain":"438.18146"},"metadata":{}}]},{"cell_type":"code","source":"# Before you start training, configure and compile the model using Keras Model.compile.\n# Set the optimizer class to adam, set the loss to the loss_fn function you defined\n# earlier, and specify a metric to be evaluated for the model by setting the metrics\n# parameter to accuracy.\nmodel.compile(optimizer='adam',\n              loss=loss_fn,\n              metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2023-07-27T13:33:57.612188Z","iopub.execute_input":"2023-07-27T13:33:57.612542Z","iopub.status.idle":"2023-07-27T13:33:57.973270Z","shell.execute_reply.started":"2023-07-27T13:33:57.612515Z","shell.execute_reply":"2023-07-27T13:33:57.972383Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"markdown","source":"### Train and evaluate the model","metadata":{}},{"cell_type":"code","source":"# Use the Model.fit method to adjust your model parameters and minimize the loss: \nmodel.fit(x_train, y_train, epochs=5)","metadata":{"execution":{"iopub.status.busy":"2023-07-27T13:57:02.920859Z","iopub.execute_input":"2023-07-27T13:57:02.921219Z","iopub.status.idle":"2023-07-27T13:57:26.052808Z","shell.execute_reply.started":"2023-07-27T13:57:02.921191Z","shell.execute_reply":"2023-07-27T13:57:26.051924Z"},"trusted":true},"execution_count":38,"outputs":[{"name":"stdout","text":"Epoch 1/5\nWARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7902834630a0> and will run it as-is.\nCause: Unable to locate the source code of <function Model.make_train_function.<locals>.train_function at 0x7902834630a0>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\nTo silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n1875/1875 [==============================] - 5s 2ms/step - loss: 2.4432 - accuracy: 0.7389\nEpoch 2/5\n1875/1875 [==============================] - 4s 2ms/step - loss: 0.5658 - accuracy: 0.8529\nEpoch 3/5\n1875/1875 [==============================] - 4s 2ms/step - loss: 0.4539 - accuracy: 0.8803\nEpoch 4/5\n1875/1875 [==============================] - 5s 2ms/step - loss: 0.3948 - accuracy: 0.8958\nEpoch 5/5\n1875/1875 [==============================] - 4s 2ms/step - loss: 0.3818 - accuracy: 0.9027\n","output_type":"stream"},{"execution_count":38,"output_type":"execute_result","data":{"text/plain":"<keras.callbacks.History at 0x79028023c730>"},"metadata":{}}]},{"cell_type":"code","source":"# The Model.evaluate method checks the model's performance, usually on a validation set or test set.\nmodel.evaluate(x_test,  y_test, verbose=2)","metadata":{"execution":{"iopub.status.busy":"2023-07-27T13:57:28.607088Z","iopub.execute_input":"2023-07-27T13:57:28.607480Z","iopub.status.idle":"2023-07-27T13:57:29.128394Z","shell.execute_reply.started":"2023-07-27T13:57:28.607453Z","shell.execute_reply":"2023-07-27T13:57:29.127700Z"},"trusted":true},"execution_count":39,"outputs":[{"name":"stdout","text":"WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x790272ef2050> and will run it as-is.\nCause: Unable to locate the source code of <function Model.make_test_function.<locals>.test_function at 0x790272ef2050>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\nTo silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n313/313 - 0s - loss: 0.2874 - accuracy: 0.9397 - 462ms/epoch - 1ms/step\n","output_type":"stream"},{"execution_count":39,"output_type":"execute_result","data":{"text/plain":"[0.2873843312263489, 0.9397000074386597]"},"metadata":{}}]},{"cell_type":"code","source":"# If you want your model to return a probability, you can wrap the trained model,\n# and attach the softmax to it:\nprobability_model = tf.keras.Sequential([\n  model,\n  tf.keras.layers.Softmax()\n])\n\n\nprobability_model(x_test[:5])","metadata":{"execution":{"iopub.status.busy":"2023-07-27T13:59:04.882916Z","iopub.execute_input":"2023-07-27T13:59:04.883293Z","iopub.status.idle":"2023-07-27T13:59:04.915738Z","shell.execute_reply.started":"2023-07-27T13:59:04.883266Z","shell.execute_reply":"2023-07-27T13:59:04.915137Z"},"trusted":true},"execution_count":40,"outputs":[{"execution_count":40,"output_type":"execute_result","data":{"text/plain":"<tf.Tensor: shape=(5, 10), dtype=float32, numpy=\narray([[0.0000000e+00, 4.8945771e-21, 2.0332876e-11, 4.5293188e-13,\n        4.9698682e-23, 7.1345559e-16, 0.0000000e+00, 1.0000000e+00,\n        3.5472360e-26, 2.1768643e-15],\n       [1.5356455e-16, 1.3054944e-09, 1.0000000e+00, 2.3280184e-13,\n        0.0000000e+00, 1.2906708e-21, 4.6287240e-20, 1.0765966e-19,\n        8.9410205e-25, 0.0000000e+00],\n       [1.8049276e-27, 1.0000000e+00, 8.5618057e-17, 4.4635979e-25,\n        3.2449359e-26, 1.0045996e-15, 3.5536586e-17, 7.6811832e-13,\n        6.6989707e-09, 5.3169085e-35],\n       [9.9997818e-01, 1.4278572e-24, 2.0502755e-05, 1.9252584e-09,\n        1.1850655e-13, 1.1764952e-07, 2.4682012e-07, 9.4471545e-07,\n        2.1339719e-08, 5.5052602e-09],\n       [4.1882301e-23, 1.4297512e-12, 5.6475596e-10, 8.7771228e-11,\n        9.9927241e-01, 9.8131963e-12, 8.2167450e-17, 4.3304282e-04,\n        3.8746903e-16, 2.9464788e-04]], dtype=float32)>"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}